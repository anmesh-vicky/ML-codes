{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing multiple linear regression using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030 8\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Name : ANMESH CHOUDHURY\n",
    "Roll No: 16NA30003\n",
    "\n",
    "Assignment 1a\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "You will not import any other library other than these provided.\n",
    "\n",
    "We provide the concrete_dataset as an example.\n",
    "There are 8 dependent variables columns(1-8).\n",
    "The last column (concrete compressive strength) is the value we wish to estimate.\n",
    "'''\n",
    "\n",
    "df= pd.read_csv('Concrete_Data.csv')\n",
    "df.head()\n",
    "\n",
    "# reads the file and stores in 2 numpy arrays.\n",
    "# X has the input features and Y has the output value in numpy array\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "Y = df.iloc[:,-1].values\n",
    "\n",
    "rows,cols= X.shape\n",
    "# how to get the number of rows and columns in the dataset.\n",
    "# Rows correspond to the number of input instances, columns correspond to the feature of an input\n",
    "\n",
    "print(rows,cols)\n",
    "\n",
    "np.random.seed(42) # to ensure that the same seed is generated\n",
    "\n",
    "# write code to shuffle the dataset\n",
    "\n",
    "def shuffle_dataset(X,Y):\n",
    "\n",
    "    s = np.random.permutation(X.shape[0])\n",
    " \n",
    "    X1=X[s]\n",
    "    Y1=Y[s]\n",
    "    \n",
    "    return X1,Y1\n",
    "    pass\n",
    "X,Y=shuffle_dataset(X,Y)\n",
    "training_size = int(0.8*rows)\n",
    "X_train = X[:training_size]\n",
    "y_train = Y[:training_size]\n",
    "X_test = X[training_size:]\n",
    "y_test = Y[training_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Linear Regression class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self):\n",
    "        #Initialize all parameters\n",
    "        \n",
    "        \n",
    "        self.w = np.random.uniform(-1,1,(8,1))\n",
    "        self.b = np.random.uniform(-1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (np.matmul(x,self.w)+self.b)\n",
    "        # Complete this function \n",
    "        \n",
    "        raise NotImplementedError\n",
    "        \n",
    "    \n",
    "    def backward(self, x, ypred, y_train, lr):\n",
    "        x1=x*(ypred-y_train)\n",
    "        \n",
    "        self.w=self.w-2*lr*np.reshape(np.mean(x1,axis=0),(8,1))\n",
    "        self.b=self.b-lr*2*np.mean((ypred-y_train))\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    def MSELoss(self,y,ypred):\n",
    "       \n",
    "        return np.mean(np.multiply((ypred-y),(ypred-y)))\n",
    "        # Compute the mean squared error \n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training with Gradient Descent\n",
      "Loss fuction decrease after 10000 epochs of training\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdLIDA1J0sgMDUnSyP4/hUiEXW9RYAgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1914cf70da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss: 426.276907885\n",
      "Starting to test\n",
      "Final test loss: 340.615817768\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of epochs as well as the learning rate. \n",
    "# Keep the values fixed.\n",
    "\n",
    "print('Starting Training with Gradient Descent')\n",
    "lreg = LinearRegression()\n",
    "epochs = 10000\n",
    "learning_rate = 0.0000001\n",
    "\n",
    "loss_history = []\n",
    "epoch_history = []\n",
    "\n",
    "# Gradient Descent\n",
    "for e in range(epochs):\n",
    "    ypred = lreg.forward(X_train) \n",
    "    ypred=np.reshape(ypred,(824,1))\n",
    "    y_train=np.reshape(y_train,(824,1))\n",
    "    loss = lreg.MSELoss(y_train,ypred) # computes the MSE loss between the actual and predicted values\n",
    "    # store the values of loss per epoch\n",
    "    if e==0 or (e+1)%100==0:\n",
    "        loss_history.append(loss)\n",
    "        epoch_history.append(e+1)\n",
    "        \n",
    "    \n",
    "    lreg.backward(X_train, ypred, y_train, learning_rate)\n",
    "\n",
    "print('Loss fuction decrease after ' + str(epochs) + ' epochs of training')\n",
    "#Plot the decrease in loss with epoch\n",
    "plt.plot(epoch_history, loss_history)\n",
    "plt.show()\n",
    "\n",
    "   \n",
    "y_train_loss= lreg.MSELoss(Y,ypred)\n",
    "print('Final training loss: '+str(y_train_loss))\n",
    "print('Starting to test')\n",
    "ytest_pred= lreg.forward(X_test)\n",
    "loss=lreg.MSELoss(y_test, ytest_pred)\n",
    "print('Final test loss: ' + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
